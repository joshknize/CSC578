{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Josh Knize and Pradyumn Pathak Final Project Submission\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to libraries\n",
    "### We have used the following libraries in this project:\n",
    "* **`Detectron 2`: Is developed and maintained by FaceBook Research**\n",
    "    * The reason this was chosen because of the modularity it provides and the plethora of model configurations it gives access to\n",
    "    * Each model option is deeply cunfigurable down to the different architectural blocks\n",
    "    * It also has support for loading in custom backbone without minimum codebased change in that of `detectron2` itself\n",
    "    * All these benefits made it an ideal choice for us, as it made integration of our custom `HebbNet` bacbone much easier\n",
    "* **`Matplotlib`: Is a real standard library used for showcasing output images**\n",
    "* **`torch`: is the work engine of `detectron2` and most of Deep Learning libraries**|\n",
    "* **`numpy`: Is used again as another work engine of torch itself, but also is used for performing various linear algebric functions throughout the project**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Setup:\n",
    "\n",
    "We would recommend creating a virtual environment for this notebook:\n",
    "* Recomended `Python=3.8`\n",
    "* Recomended OS: `Linux` \n",
    "    * This version uses `detectron2` which only support `pip install` on `Linux`, and need to be built from source on windows.\n",
    "    * Official guide to building on windows can be found ([Here](URL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'detectron2' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Downloading Dataset (This might take a while)\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1MM6kODxnDvkVzzOuOYYbwrP5uou1DOC-\n",
      "From (redirected): https://drive.google.com/uc?id=1MM6kODxnDvkVzzOuOYYbwrP5uou1DOC-&confirm=t&uuid=3a873b66-4808-41ea-b21f-3bf79a4f348d\n",
      "To: d:\\College\\Assignments\\NNDL_Project\\datasets.zip\n",
      "\n",
      "  0%|          | 0.00/720M [00:00<?, ?B/s]\n",
      "  0%|          | 524k/720M [00:00<03:25, 3.50MB/s]\n",
      "  0%|          | 1.05M/720M [00:00<03:33, 3.37MB/s]\n",
      "  0%|          | 1.57M/720M [00:00<03:20, 3.58MB/s]\n",
      "  0%|          | 2.10M/720M [00:00<03:05, 3.86MB/s]\n",
      "  0%|          | 2.62M/720M [00:00<02:53, 4.14MB/s]\n",
      "  1%|          | 3.67M/720M [00:00<02:33, 4.66MB/s]\n",
      "  1%|          | 4.19M/720M [00:00<02:33, 4.65MB/s]\n",
      "  1%|          | 5.24M/720M [00:01<02:20, 5.07MB/s]\n",
      "  1%|          | 6.29M/720M [00:01<02:16, 5.24MB/s]\n",
      "  1%|          | 7.34M/720M [00:01<01:59, 5.95MB/s]\n",
      "  1%|          | 8.39M/720M [00:01<01:58, 5.98MB/s]\n",
      "  1%|▏         | 9.44M/720M [00:01<01:50, 6.43MB/s]\n",
      "  1%|▏         | 10.5M/720M [00:01<01:51, 6.37MB/s]\n",
      "  2%|▏         | 11.5M/720M [00:02<01:55, 6.14MB/s]\n",
      "  2%|▏         | 12.6M/720M [00:02<01:48, 6.52MB/s]\n",
      "  2%|▏         | 13.6M/720M [00:02<01:48, 6.52MB/s]\n",
      "  2%|▏         | 14.7M/720M [00:02<01:45, 6.71MB/s]\n",
      "  2%|▏         | 15.7M/720M [00:02<01:41, 6.94MB/s]\n",
      "  2%|▏         | 16.8M/720M [00:02<01:43, 6.80MB/s]\n",
      "  2%|▏         | 17.8M/720M [00:03<01:36, 7.24MB/s]\n",
      "  3%|▎         | 18.9M/720M [00:03<01:34, 7.41MB/s]\n",
      "  3%|▎         | 19.9M/720M [00:03<01:39, 7.00MB/s]\n",
      "  3%|▎         | 21.0M/720M [00:03<01:40, 6.94MB/s]\n",
      "  3%|▎         | 22.0M/720M [00:03<01:42, 6.78MB/s]\n",
      "  3%|▎         | 23.1M/720M [00:03<02:01, 5.74MB/s]\n",
      "  3%|▎         | 24.1M/720M [00:04<01:47, 6.45MB/s]\n",
      "  3%|▎         | 25.2M/720M [00:04<01:39, 6.97MB/s]\n",
      "  4%|▎         | 26.2M/720M [00:04<01:35, 7.28MB/s]\n",
      "  4%|▍         | 27.3M/720M [00:04<01:33, 7.43MB/s]\n",
      "  4%|▍         | 28.3M/720M [00:04<01:29, 7.73MB/s]\n",
      "  4%|▍         | 29.4M/720M [00:04<01:27, 7.88MB/s]\n",
      "  4%|▍         | 30.4M/720M [00:04<01:35, 7.24MB/s]\n",
      "  4%|▍         | 31.5M/720M [00:04<01:32, 7.41MB/s]\n",
      "  5%|▍         | 32.5M/720M [00:05<01:39, 6.89MB/s]\n",
      "  5%|▍         | 33.6M/720M [00:05<01:46, 6.46MB/s]\n",
      "  5%|▍         | 34.6M/720M [00:05<01:45, 6.49MB/s]\n",
      "  5%|▍         | 35.7M/720M [00:05<01:42, 6.67MB/s]\n",
      "  5%|▌         | 36.7M/720M [00:05<01:42, 6.66MB/s]\n",
      "  5%|▌         | 37.7M/720M [00:05<01:48, 6.31MB/s]\n",
      "  5%|▌         | 38.8M/720M [00:06<01:39, 6.85MB/s]\n",
      "  6%|▌         | 39.8M/720M [00:06<01:33, 7.24MB/s]\n",
      "  6%|▌         | 40.9M/720M [00:06<01:27, 7.73MB/s]\n",
      "  6%|▌         | 42.5M/720M [00:06<01:27, 7.78MB/s]\n",
      "  6%|▌         | 43.5M/720M [00:06<01:35, 7.08MB/s]\n",
      "  6%|▌         | 44.6M/720M [00:07<02:04, 5.42MB/s]\n",
      "  6%|▋         | 45.6M/720M [00:07<02:25, 4.64MB/s]\n",
      "  6%|▋         | 46.7M/720M [00:07<02:18, 4.87MB/s]\n",
      "  7%|▋         | 47.7M/720M [00:07<02:13, 5.02MB/s]\n",
      "  7%|▋         | 48.8M/720M [00:07<02:05, 5.34MB/s]\n",
      "  7%|▋         | 49.8M/720M [00:08<02:07, 5.26MB/s]\n",
      "  7%|▋         | 50.9M/720M [00:08<02:02, 5.48MB/s]\n",
      "  7%|▋         | 51.9M/720M [00:08<01:58, 5.64MB/s]\n",
      "  7%|▋         | 53.0M/720M [00:08<01:55, 5.77MB/s]\n",
      "  8%|▊         | 54.0M/720M [00:08<02:02, 5.43MB/s]\n",
      "  8%|▊         | 55.1M/720M [00:09<02:16, 4.88MB/s]\n",
      "  8%|▊         | 56.1M/720M [00:09<02:06, 5.25MB/s]\n",
      "  8%|▊         | 57.1M/720M [00:09<02:03, 5.36MB/s]\n",
      "  8%|▊         | 58.2M/720M [00:09<02:07, 5.18MB/s]\n",
      "  8%|▊         | 59.2M/720M [00:09<02:18, 4.75MB/s]\n",
      "  8%|▊         | 60.3M/720M [00:10<02:07, 5.19MB/s]\n",
      "  9%|▊         | 61.3M/720M [00:10<02:08, 5.12MB/s]\n",
      "  9%|▊         | 62.4M/720M [00:10<02:12, 4.95MB/s]\n",
      "  9%|▊         | 62.9M/720M [00:10<02:16, 4.81MB/s]\n",
      "  9%|▉         | 64.0M/720M [00:10<02:07, 5.13MB/s]\n",
      "  9%|▉         | 65.0M/720M [00:10<01:56, 5.61MB/s]\n",
      "  9%|▉         | 66.1M/720M [00:11<01:50, 5.93MB/s]\n",
      "  9%|▉         | 67.1M/720M [00:11<01:45, 6.17MB/s]\n",
      "  9%|▉         | 68.2M/720M [00:11<01:41, 6.45MB/s]\n",
      " 10%|▉         | 69.2M/720M [00:11<01:38, 6.59MB/s]\n",
      " 10%|▉         | 70.3M/720M [00:11<01:38, 6.58MB/s]\n",
      " 10%|▉         | 71.3M/720M [00:11<01:30, 7.13MB/s]\n",
      " 10%|█         | 72.4M/720M [00:11<01:29, 7.23MB/s]\n",
      " 10%|█         | 73.4M/720M [00:12<02:14, 4.80MB/s]\n",
      " 10%|█         | 74.4M/720M [00:12<02:12, 4.86MB/s]\n",
      " 10%|█         | 75.5M/720M [00:12<02:14, 4.80MB/s]\n",
      " 11%|█         | 76.5M/720M [00:12<02:04, 5.15MB/s]\n",
      " 11%|█         | 77.6M/720M [00:13<02:10, 4.92MB/s]\n",
      " 11%|█         | 78.6M/720M [00:13<01:56, 5.48MB/s]\n",
      " 11%|█         | 79.7M/720M [00:13<02:34, 4.13MB/s]\n",
      " 11%|█         | 80.7M/720M [00:13<02:13, 4.77MB/s]\n",
      " 11%|█▏        | 81.8M/720M [00:14<02:07, 4.99MB/s]\n",
      " 12%|█▏        | 82.8M/720M [00:14<02:07, 5.01MB/s]\n",
      " 12%|█▏        | 83.9M/720M [00:14<02:00, 5.28MB/s]\n",
      " 12%|█▏        | 84.9M/720M [00:14<02:02, 5.17MB/s]\n",
      " 12%|█▏        | 86.0M/720M [00:14<01:52, 5.65MB/s]\n",
      " 12%|█▏        | 87.0M/720M [00:15<01:50, 5.73MB/s]\n",
      " 12%|█▏        | 88.1M/720M [00:15<01:55, 5.48MB/s]\n",
      " 12%|█▏        | 89.1M/720M [00:15<01:58, 5.32MB/s]\n",
      " 13%|█▎        | 90.2M/720M [00:15<01:50, 5.69MB/s]\n",
      " 13%|█▎        | 91.2M/720M [00:15<01:44, 5.99MB/s]\n",
      " 13%|█▎        | 92.3M/720M [00:15<01:40, 6.22MB/s]\n",
      " 13%|█▎        | 93.3M/720M [00:16<01:38, 6.35MB/s]\n",
      " 13%|█▎        | 94.4M/720M [00:16<01:33, 6.69MB/s]\n",
      " 13%|█▎        | 95.4M/720M [00:16<01:39, 6.26MB/s]\n",
      " 13%|█▎        | 96.5M/720M [00:16<01:36, 6.42MB/s]\n",
      " 14%|█▎        | 97.5M/720M [00:16<01:32, 6.76MB/s]\n",
      " 14%|█▎        | 98.6M/720M [00:16<01:30, 6.89MB/s]\n",
      " 14%|█▍        | 99.6M/720M [00:16<01:24, 7.34MB/s]\n",
      " 14%|█▍        | 101M/720M [00:17<01:27, 7.06MB/s] \n",
      " 14%|█▍        | 102M/720M [00:17<01:23, 7.38MB/s]\n",
      " 14%|█▍        | 103M/720M [00:17<01:21, 7.54MB/s]\n",
      " 14%|█▍        | 104M/720M [00:17<01:27, 7.02MB/s]\n",
      " 15%|█▍        | 105M/720M [00:17<01:35, 6.43MB/s]\n",
      " 15%|█▍        | 106M/720M [00:17<01:30, 6.81MB/s]\n",
      " 15%|█▍        | 107M/720M [00:17<01:22, 7.42MB/s]\n",
      " 15%|█▌        | 108M/720M [00:18<01:25, 7.12MB/s]\n",
      " 15%|█▌        | 109M/720M [00:18<01:23, 7.30MB/s]\n",
      " 15%|█▌        | 110M/720M [00:18<01:17, 7.84MB/s]\n",
      " 16%|█▌        | 112M/720M [00:18<01:08, 8.86MB/s]\n",
      " 16%|█▌        | 113M/720M [00:18<01:09, 8.79MB/s]\n",
      " 16%|█▌        | 114M/720M [00:18<01:09, 8.72MB/s]\n",
      " 16%|█▌        | 115M/720M [00:18<01:09, 8.76MB/s]\n",
      " 16%|█▌        | 116M/720M [00:19<01:11, 8.43MB/s]\n",
      " 16%|█▌        | 117M/720M [00:19<01:17, 7.76MB/s]\n",
      " 16%|█▋        | 118M/720M [00:19<01:17, 7.77MB/s]\n",
      " 17%|█▋        | 119M/720M [00:19<01:16, 7.84MB/s]\n",
      " 17%|█▋        | 120M/720M [00:19<01:21, 7.37MB/s]\n",
      " 17%|█▋        | 121M/720M [00:19<01:23, 7.18MB/s]\n",
      " 17%|█▋        | 122M/720M [00:19<01:25, 7.02MB/s]\n",
      " 17%|█▋        | 123M/720M [00:20<01:18, 7.55MB/s]\n",
      " 17%|█▋        | 124M/720M [00:20<01:16, 7.82MB/s]\n",
      " 17%|█▋        | 126M/720M [00:20<01:08, 8.61MB/s]\n",
      " 18%|█▊        | 127M/720M [00:20<01:26, 6.84MB/s]\n",
      " 18%|█▊        | 128M/720M [00:20<01:50, 5.35MB/s]\n",
      " 18%|█▊        | 129M/720M [00:21<01:47, 5.48MB/s]\n",
      " 18%|█▊        | 130M/720M [00:21<01:44, 5.62MB/s]\n",
      " 18%|█▊        | 131M/720M [00:21<01:34, 6.25MB/s]\n",
      " 18%|█▊        | 132M/720M [00:21<01:37, 6.05MB/s]\n",
      " 19%|█▊        | 133M/720M [00:21<01:31, 6.38MB/s]\n",
      " 19%|█▊        | 134M/720M [00:21<01:25, 6.82MB/s]\n",
      " 19%|█▉        | 135M/720M [00:21<01:27, 6.66MB/s]\n",
      " 19%|█▉        | 136M/720M [00:22<01:20, 7.24MB/s]\n",
      " 19%|█▉        | 138M/720M [00:22<01:10, 8.25MB/s]\n",
      " 19%|█▉        | 139M/720M [00:22<01:15, 7.73MB/s]\n",
      " 20%|█▉        | 141M/720M [00:22<01:07, 8.59MB/s]\n",
      " 20%|█▉        | 142M/720M [00:22<01:06, 8.73MB/s]\n",
      " 20%|█▉        | 143M/720M [00:22<01:06, 8.72MB/s]\n",
      " 20%|█▉        | 144M/720M [00:22<01:05, 8.75MB/s]\n",
      " 20%|██        | 145M/720M [00:23<01:07, 8.52MB/s]\n",
      " 20%|██        | 146M/720M [00:23<01:05, 8.70MB/s]\n",
      " 20%|██        | 147M/720M [00:23<01:06, 8.63MB/s]\n",
      " 21%|██        | 148M/720M [00:23<01:06, 8.62MB/s]\n",
      " 21%|██        | 149M/720M [00:23<01:07, 8.46MB/s]\n",
      " 21%|██        | 150M/720M [00:23<01:08, 8.26MB/s]\n",
      " 21%|██        | 151M/720M [00:23<01:46, 5.34MB/s]\n",
      " 21%|██        | 152M/720M [00:24<01:47, 5.30MB/s]\n",
      " 21%|██▏       | 153M/720M [00:24<01:53, 4.98MB/s]\n",
      " 21%|██▏       | 154M/720M [00:24<01:54, 4.95MB/s]\n",
      " 22%|██▏       | 155M/720M [00:24<01:50, 5.11MB/s]\n",
      " 22%|██▏       | 156M/720M [00:25<01:56, 4.84MB/s]\n",
      " 22%|██▏       | 157M/720M [00:25<01:49, 5.12MB/s]\n",
      " 22%|██▏       | 158M/720M [00:25<01:46, 5.25MB/s]\n",
      " 22%|██▏       | 159M/720M [00:25<01:46, 5.24MB/s]\n",
      " 22%|██▏       | 160M/720M [00:26<02:12, 4.22MB/s]\n",
      " 22%|██▏       | 161M/720M [00:26<02:10, 4.28MB/s]\n",
      " 23%|██▎       | 163M/720M [00:26<01:54, 4.85MB/s]\n",
      " 23%|██▎       | 164M/720M [00:26<01:48, 5.13MB/s]\n",
      " 23%|██▎       | 165M/720M [00:26<01:54, 4.86MB/s]\n",
      " 23%|██▎       | 166M/720M [00:26<01:41, 5.44MB/s]\n",
      " 23%|██▎       | 167M/720M [00:27<01:30, 6.12MB/s]\n",
      " 23%|██▎       | 168M/720M [00:27<01:26, 6.38MB/s]\n",
      " 23%|██▎       | 169M/720M [00:27<01:23, 6.58MB/s]\n",
      " 24%|██▎       | 170M/720M [00:27<01:36, 5.72MB/s]\n",
      " 24%|██▍       | 171M/720M [00:27<01:36, 5.67MB/s]\n",
      " 24%|██▍       | 172M/720M [00:27<01:35, 5.73MB/s]\n",
      " 24%|██▍       | 173M/720M [00:28<01:35, 5.71MB/s]\n",
      " 24%|██▍       | 174M/720M [00:28<01:36, 5.67MB/s]\n",
      " 24%|██▍       | 175M/720M [00:28<01:35, 5.68MB/s]\n",
      " 24%|██▍       | 176M/720M [00:28<01:36, 5.66MB/s]\n",
      " 25%|██▍       | 177M/720M [00:28<01:32, 5.88MB/s]\n",
      " 25%|██▍       | 178M/720M [00:29<01:24, 6.41MB/s]\n",
      " 25%|██▍       | 179M/720M [00:29<01:28, 6.09MB/s]\n",
      " 25%|██▌       | 180M/720M [00:29<01:31, 5.88MB/s]\n",
      " 25%|██▌       | 181M/720M [00:29<01:38, 5.47MB/s]\n",
      " 25%|██▌       | 182M/720M [00:29<01:32, 5.82MB/s]\n",
      " 26%|██▌       | 184M/720M [00:29<01:32, 5.82MB/s]\n",
      " 26%|██▌       | 185M/720M [00:30<01:30, 5.90MB/s]\n",
      " 26%|██▌       | 186M/720M [00:30<01:27, 6.07MB/s]\n",
      " 26%|██▌       | 187M/720M [00:30<01:33, 5.68MB/s]\n",
      " 26%|██▌       | 188M/720M [00:30<01:33, 5.71MB/s]\n",
      " 26%|██▌       | 189M/720M [00:30<01:43, 5.15MB/s]\n",
      " 26%|██▋       | 190M/720M [00:31<01:31, 5.79MB/s]\n",
      " 27%|██▋       | 191M/720M [00:31<01:38, 5.39MB/s]\n",
      " 27%|██▋       | 192M/720M [00:31<01:28, 5.95MB/s]\n",
      " 27%|██▋       | 193M/720M [00:31<01:21, 6.50MB/s]\n",
      " 27%|██▋       | 194M/720M [00:31<01:16, 6.91MB/s]\n",
      " 27%|██▋       | 195M/720M [00:32<01:46, 4.90MB/s]\n",
      " 27%|██▋       | 196M/720M [00:32<01:48, 4.81MB/s]\n",
      " 27%|██▋       | 197M/720M [00:32<01:35, 5.44MB/s]\n",
      " 28%|██▊       | 198M/720M [00:32<01:34, 5.49MB/s]\n",
      " 28%|██▊       | 199M/720M [00:32<01:31, 5.72MB/s]\n",
      " 28%|██▊       | 200M/720M [00:32<01:23, 6.25MB/s]\n",
      " 28%|██▊       | 201M/720M [00:33<01:20, 6.41MB/s]\n",
      " 28%|██▊       | 202M/720M [00:33<01:19, 6.49MB/s]\n",
      " 28%|██▊       | 203M/720M [00:33<01:13, 7.03MB/s]\n",
      " 28%|██▊       | 204M/720M [00:33<01:09, 7.36MB/s]\n",
      " 29%|██▊       | 206M/720M [00:33<01:33, 5.51MB/s]\n",
      " 29%|██▊       | 207M/720M [00:33<01:23, 6.14MB/s]\n",
      " 29%|██▉       | 208M/720M [00:33<01:15, 6.76MB/s]\n",
      " 29%|██▉       | 209M/720M [00:34<01:14, 6.87MB/s]\n",
      " 29%|██▉       | 210M/720M [00:34<01:10, 7.27MB/s]\n",
      " 29%|██▉       | 211M/720M [00:34<01:14, 6.82MB/s]\n",
      " 29%|██▉       | 212M/720M [00:34<01:16, 6.63MB/s]\n",
      " 30%|██▉       | 213M/720M [00:34<01:14, 6.76MB/s]\n",
      " 30%|██▉       | 214M/720M [00:34<01:09, 7.27MB/s]\n",
      " 30%|██▉       | 215M/720M [00:35<01:16, 6.58MB/s]\n",
      " 30%|███       | 216M/720M [00:35<01:17, 6.47MB/s]\n",
      " 30%|███       | 217M/720M [00:35<01:19, 6.34MB/s]\n",
      " 30%|███       | 218M/720M [00:35<01:22, 6.09MB/s]\n",
      " 30%|███       | 219M/720M [00:35<01:14, 6.72MB/s]\n",
      " 31%|███       | 220M/720M [00:35<01:08, 7.30MB/s]\n",
      " 31%|███       | 221M/720M [00:35<01:04, 7.72MB/s]\n",
      " 31%|███       | 222M/720M [00:36<00:59, 8.37MB/s]\n",
      " 31%|███       | 223M/720M [00:36<01:02, 7.92MB/s]\n",
      " 31%|███       | 224M/720M [00:36<01:02, 7.93MB/s]\n",
      " 31%|███▏      | 225M/720M [00:36<01:04, 7.72MB/s]\n",
      " 31%|███▏      | 226M/720M [00:36<00:59, 8.25MB/s]\n",
      " 32%|███▏      | 228M/720M [00:36<00:59, 8.21MB/s]\n",
      " 32%|███▏      | 229M/720M [00:36<00:59, 8.23MB/s]\n",
      " 32%|███▏      | 230M/720M [00:36<01:05, 7.50MB/s]\n",
      " 32%|███▏      | 231M/720M [00:37<01:06, 7.40MB/s]\n",
      " 32%|███▏      | 232M/720M [00:37<01:08, 7.12MB/s]\n",
      " 32%|███▏      | 233M/720M [00:37<01:07, 7.24MB/s]\n",
      " 32%|███▏      | 234M/720M [00:37<01:11, 6.81MB/s]\n",
      " 33%|███▎      | 235M/720M [00:37<01:08, 7.08MB/s]\n",
      " 33%|███▎      | 236M/720M [00:37<01:11, 6.77MB/s]\n",
      " 33%|███▎      | 237M/720M [00:38<01:06, 7.27MB/s]\n",
      " 33%|███▎      | 238M/720M [00:38<01:02, 7.76MB/s]\n",
      " 33%|███▎      | 240M/720M [00:38<01:01, 7.80MB/s]\n",
      " 33%|███▎      | 241M/720M [00:38<01:08, 7.02MB/s]\n",
      " 34%|███▎      | 242M/720M [00:38<01:04, 7.38MB/s]\n",
      " 34%|███▎      | 243M/720M [00:38<01:10, 6.79MB/s]\n",
      " 34%|███▍      | 244M/720M [00:38<01:06, 7.13MB/s]\n",
      " 34%|███▍      | 245M/720M [00:39<01:13, 6.48MB/s]\n",
      " 34%|███▍      | 246M/720M [00:39<01:14, 6.35MB/s]\n",
      " 34%|███▍      | 247M/720M [00:39<01:39, 4.73MB/s]\n",
      " 34%|███▍      | 248M/720M [00:39<01:32, 5.11MB/s]\n",
      " 35%|███▍      | 249M/720M [00:39<01:21, 5.74MB/s]\n",
      " 35%|███▍      | 250M/720M [00:40<01:22, 5.72MB/s]\n",
      " 35%|███▍      | 251M/720M [00:40<01:21, 5.73MB/s]\n",
      " 35%|███▌      | 252M/720M [00:40<01:16, 6.11MB/s]\n",
      " 35%|███▌      | 253M/720M [00:40<01:16, 6.06MB/s]\n",
      " 35%|███▌      | 254M/720M [00:40<01:10, 6.57MB/s]\n",
      " 35%|███▌      | 255M/720M [00:40<01:13, 6.33MB/s]\n",
      " 36%|███▌      | 256M/720M [00:41<01:07, 6.85MB/s]\n",
      " 36%|███▌      | 257M/720M [00:41<01:10, 6.53MB/s]\n",
      " 36%|███▌      | 258M/720M [00:41<01:13, 6.29MB/s]\n",
      " 36%|███▌      | 260M/720M [00:41<01:09, 6.62MB/s]\n",
      " 36%|███▌      | 261M/720M [00:41<01:09, 6.62MB/s]\n",
      " 36%|███▋      | 262M/720M [00:41<01:07, 6.77MB/s]\n",
      " 37%|███▋      | 263M/720M [00:42<01:00, 7.51MB/s]\n",
      " 37%|███▋      | 264M/720M [00:42<00:56, 8.02MB/s]\n",
      " 37%|███▋      | 265M/720M [00:42<00:52, 8.64MB/s]\n",
      " 37%|███▋      | 266M/720M [00:42<00:53, 8.51MB/s]\n",
      " 37%|███▋      | 267M/720M [00:42<00:52, 8.54MB/s]\n",
      " 37%|███▋      | 268M/720M [00:42<00:57, 7.88MB/s]\n",
      " 37%|███▋      | 269M/720M [00:42<00:57, 7.86MB/s]\n",
      " 38%|███▊      | 271M/720M [00:42<00:56, 7.96MB/s]\n",
      " 38%|███▊      | 272M/720M [00:43<00:57, 7.84MB/s]\n",
      " 38%|███▊      | 273M/720M [00:43<00:58, 7.65MB/s]\n",
      " 38%|███▊      | 274M/720M [00:43<01:05, 6.80MB/s]\n",
      " 38%|███▊      | 275M/720M [00:43<01:00, 7.30MB/s]\n",
      " 38%|███▊      | 276M/720M [00:43<01:15, 5.90MB/s]\n",
      " 38%|███▊      | 277M/720M [00:43<01:08, 6.42MB/s]\n",
      " 39%|███▊      | 278M/720M [00:44<01:08, 6.48MB/s]\n",
      " 39%|███▉      | 279M/720M [00:44<01:05, 6.73MB/s]\n",
      " 39%|███▉      | 280M/720M [00:44<01:01, 7.10MB/s]\n",
      " 39%|███▉      | 281M/720M [00:44<00:57, 7.59MB/s]\n",
      " 39%|███▉      | 282M/720M [00:44<01:00, 7.23MB/s]\n",
      " 39%|███▉      | 283M/720M [00:44<01:16, 5.71MB/s]\n",
      " 39%|███▉      | 284M/720M [00:45<01:14, 5.86MB/s]\n",
      " 40%|███▉      | 285M/720M [00:45<01:06, 6.52MB/s]\n",
      " 40%|███▉      | 286M/720M [00:45<01:08, 6.30MB/s]\n",
      " 40%|████      | 288M/720M [00:45<01:01, 7.01MB/s]\n",
      " 40%|████      | 289M/720M [00:45<00:56, 7.68MB/s]\n",
      " 40%|████      | 290M/720M [00:45<00:53, 7.98MB/s]\n",
      " 40%|████      | 291M/720M [00:45<00:53, 8.07MB/s]\n",
      " 41%|████      | 292M/720M [00:46<00:58, 7.33MB/s]\n",
      " 41%|████      | 293M/720M [00:46<00:55, 7.70MB/s]\n",
      " 41%|████      | 294M/720M [00:46<00:52, 8.11MB/s]\n",
      " 41%|████      | 295M/720M [00:46<00:51, 8.27MB/s]\n",
      " 41%|████      | 296M/720M [00:46<00:49, 8.53MB/s]\n",
      " 41%|████▏     | 297M/720M [00:46<00:50, 8.39MB/s]\n",
      " 42%|████▏     | 299M/720M [00:46<00:45, 9.15MB/s]\n",
      " 42%|████▏     | 300M/720M [00:46<00:46, 8.95MB/s]\n",
      " 42%|████▏     | 301M/720M [00:47<00:45, 9.17MB/s]\n",
      " 42%|████▏     | 302M/720M [00:47<00:45, 9.08MB/s]\n",
      " 42%|████▏     | 303M/720M [00:47<00:46, 8.88MB/s]\n",
      " 42%|████▏     | 304M/720M [00:47<00:51, 8.00MB/s]\n",
      " 42%|████▏     | 305M/720M [00:47<00:53, 7.68MB/s]\n",
      " 43%|████▎     | 306M/720M [00:47<00:51, 7.97MB/s]\n",
      " 43%|████▎     | 307M/720M [00:47<00:49, 8.26MB/s]\n",
      " 43%|████▎     | 308M/720M [00:47<00:49, 8.23MB/s]\n",
      " 43%|████▎     | 309M/720M [00:48<00:54, 7.52MB/s]\n",
      " 43%|████▎     | 311M/720M [00:48<00:46, 8.71MB/s]\n",
      " 43%|████▎     | 312M/720M [00:48<00:47, 8.49MB/s]\n",
      " 43%|████▎     | 313M/720M [00:48<00:47, 8.50MB/s]\n",
      " 44%|████▎     | 314M/720M [00:48<00:47, 8.54MB/s]\n",
      " 44%|████▍     | 315M/720M [00:48<00:53, 7.49MB/s]\n",
      " 44%|████▍     | 316M/720M [00:48<00:52, 7.75MB/s]\n",
      " 44%|████▍     | 317M/720M [00:49<00:51, 7.87MB/s]\n",
      " 44%|████▍     | 318M/720M [00:49<00:55, 7.27MB/s]\n",
      " 44%|████▍     | 319M/720M [00:49<00:52, 7.67MB/s]\n",
      " 45%|████▍     | 320M/720M [00:49<00:50, 7.90MB/s]\n",
      " 45%|████▍     | 321M/720M [00:49<00:57, 6.93MB/s]\n",
      " 45%|████▍     | 322M/720M [00:49<00:52, 7.63MB/s]\n",
      " 45%|████▍     | 323M/720M [00:49<00:51, 7.67MB/s]\n",
      " 45%|████▌     | 325M/720M [00:50<00:49, 7.97MB/s]\n",
      " 45%|████▌     | 326M/720M [00:50<00:49, 7.90MB/s]\n",
      " 45%|████▌     | 327M/720M [00:50<00:48, 8.07MB/s]\n",
      " 46%|████▌     | 328M/720M [00:50<00:52, 7.47MB/s]\n",
      " 46%|████▌     | 329M/720M [00:50<00:46, 8.38MB/s]\n",
      " 46%|████▌     | 330M/720M [00:50<00:50, 7.66MB/s]\n",
      " 46%|████▌     | 331M/720M [00:50<00:50, 7.75MB/s]\n",
      " 46%|████▌     | 332M/720M [00:51<00:54, 7.10MB/s]\n",
      " 46%|████▋     | 333M/720M [00:51<00:56, 6.87MB/s]\n",
      " 46%|████▋     | 334M/720M [00:51<00:53, 7.24MB/s]\n",
      " 47%|████▋     | 336M/720M [00:51<00:51, 7.49MB/s]\n",
      " 47%|████▋     | 337M/720M [00:51<00:49, 7.71MB/s]\n",
      " 47%|████▋     | 338M/720M [00:51<00:47, 8.05MB/s]\n",
      " 47%|████▋     | 339M/720M [00:51<00:47, 7.95MB/s]\n",
      " 47%|████▋     | 340M/720M [00:52<00:46, 8.11MB/s]\n",
      " 47%|████▋     | 341M/720M [00:52<00:45, 8.34MB/s]\n",
      " 48%|████▊     | 342M/720M [00:52<00:45, 8.31MB/s]\n",
      " 48%|████▊     | 343M/720M [00:52<00:50, 7.45MB/s]\n",
      " 48%|████▊     | 344M/720M [00:52<01:00, 6.17MB/s]\n",
      " 48%|████▊     | 346M/720M [00:52<00:55, 6.79MB/s]\n",
      " 48%|████▊     | 347M/720M [00:53<00:52, 7.04MB/s]\n",
      " 48%|████▊     | 348M/720M [00:53<00:49, 7.53MB/s]\n",
      " 49%|████▊     | 349M/720M [00:53<00:53, 6.87MB/s]\n",
      " 49%|████▊     | 350M/720M [00:53<01:10, 5.21MB/s]\n",
      " 49%|████▉     | 351M/720M [00:53<01:01, 6.02MB/s]\n",
      " 49%|████▉     | 352M/720M [00:53<00:54, 6.79MB/s]\n",
      " 49%|████▉     | 353M/720M [00:54<00:50, 7.28MB/s]\n",
      " 49%|████▉     | 354M/720M [00:54<00:48, 7.45MB/s]\n",
      " 49%|████▉     | 355M/720M [00:54<00:47, 7.61MB/s]\n",
      " 50%|████▉     | 357M/720M [00:54<00:46, 7.86MB/s]\n",
      " 50%|████▉     | 358M/720M [00:54<00:42, 8.44MB/s]\n",
      " 50%|████▉     | 359M/720M [00:54<00:40, 8.99MB/s]\n",
      " 50%|█████     | 360M/720M [00:54<00:40, 8.95MB/s]\n",
      " 50%|█████     | 361M/720M [00:54<00:39, 8.97MB/s]\n",
      " 50%|█████     | 362M/720M [00:55<00:40, 8.88MB/s]\n",
      " 50%|█████     | 363M/720M [00:55<00:38, 9.22MB/s]\n",
      " 51%|█████     | 365M/720M [00:55<00:36, 9.78MB/s]\n",
      " 51%|█████     | 366M/720M [00:55<00:36, 9.60MB/s]\n",
      " 51%|█████     | 367M/720M [00:55<00:39, 8.86MB/s]\n",
      " 51%|█████     | 368M/720M [00:55<00:43, 8.13MB/s]\n",
      " 51%|█████▏    | 369M/720M [00:55<00:42, 8.33MB/s]\n",
      " 51%|█████▏    | 370M/720M [00:55<00:41, 8.35MB/s]\n",
      " 52%|█████▏    | 372M/720M [00:56<00:41, 8.34MB/s]\n",
      " 52%|█████▏    | 373M/720M [00:56<00:41, 8.40MB/s]\n",
      " 52%|█████▏    | 374M/720M [00:56<01:02, 5.52MB/s]\n",
      " 52%|█████▏    | 375M/720M [00:56<00:56, 6.06MB/s]\n",
      " 52%|█████▏    | 376M/720M [00:56<00:52, 6.51MB/s]\n",
      " 52%|█████▏    | 377M/720M [00:57<00:48, 7.00MB/s]\n",
      " 53%|█████▎    | 378M/720M [00:57<00:47, 7.26MB/s]\n",
      " 53%|█████▎    | 379M/720M [00:57<00:45, 7.42MB/s]\n",
      " 53%|█████▎    | 380M/720M [00:57<00:43, 7.74MB/s]\n",
      " 53%|█████▎    | 381M/720M [00:57<00:46, 7.27MB/s]\n",
      " 53%|█████▎    | 382M/720M [00:57<00:49, 6.81MB/s]\n",
      " 53%|█████▎    | 383M/720M [00:57<00:47, 7.12MB/s]\n",
      " 53%|█████▎    | 384M/720M [00:58<00:44, 7.55MB/s]\n",
      " 54%|█████▎    | 385M/720M [00:58<00:43, 7.70MB/s]\n",
      " 54%|█████▎    | 386M/720M [00:58<00:43, 7.67MB/s]\n",
      " 54%|█████▍    | 387M/720M [00:58<00:44, 7.53MB/s]\n",
      " 54%|█████▍    | 388M/720M [00:58<00:43, 7.67MB/s]\n",
      " 54%|█████▍    | 390M/720M [00:58<00:43, 7.61MB/s]\n",
      " 54%|█████▍    | 391M/720M [00:58<00:52, 6.22MB/s]\n",
      " 54%|█████▍    | 392M/720M [00:59<00:47, 6.96MB/s]\n",
      " 55%|█████▍    | 393M/720M [00:59<00:42, 7.72MB/s]\n",
      " 55%|█████▍    | 394M/720M [00:59<00:43, 7.53MB/s]\n",
      " 55%|█████▍    | 395M/720M [00:59<00:41, 7.80MB/s]\n",
      " 55%|█████▌    | 396M/720M [00:59<00:41, 7.85MB/s]\n",
      " 55%|█████▌    | 397M/720M [00:59<00:44, 7.31MB/s]\n",
      " 55%|█████▌    | 398M/720M [00:59<00:43, 7.42MB/s]\n",
      " 55%|█████▌    | 399M/720M [00:59<00:42, 7.58MB/s]\n",
      " 56%|█████▌    | 400M/720M [01:00<00:41, 7.70MB/s]\n",
      " 56%|█████▌    | 401M/720M [01:00<00:39, 7.99MB/s]\n",
      " 56%|█████▌    | 402M/720M [01:00<00:40, 7.93MB/s]\n",
      " 56%|█████▌    | 403M/720M [01:00<00:38, 8.20MB/s]\n",
      " 56%|█████▌    | 404M/720M [01:00<00:41, 7.59MB/s]\n",
      " 56%|█████▋    | 405M/720M [01:00<00:39, 7.91MB/s]\n",
      " 56%|█████▋    | 406M/720M [01:00<00:40, 7.77MB/s]\n",
      " 57%|█████▋    | 407M/720M [01:01<00:40, 7.69MB/s]\n",
      " 57%|█████▋    | 408M/720M [01:01<00:38, 8.07MB/s]\n",
      " 57%|█████▋    | 409M/720M [01:01<00:42, 7.34MB/s]\n",
      " 57%|█████▋    | 411M/720M [01:01<00:40, 7.54MB/s]\n",
      " 57%|█████▋    | 412M/720M [01:01<00:45, 6.82MB/s]\n",
      " 57%|█████▋    | 413M/720M [01:01<00:40, 7.54MB/s]\n",
      " 57%|█████▋    | 414M/720M [01:01<00:48, 6.27MB/s]\n",
      " 58%|█████▊    | 415M/720M [01:02<00:51, 5.96MB/s]\n",
      " 58%|█████▊    | 416M/720M [01:02<00:46, 6.48MB/s]\n",
      " 58%|█████▊    | 417M/720M [01:02<00:43, 6.98MB/s]\n",
      " 58%|█████▊    | 418M/720M [01:02<00:45, 6.58MB/s]\n",
      " 58%|█████▊    | 419M/720M [01:02<00:43, 6.91MB/s]\n",
      " 58%|█████▊    | 420M/720M [01:02<00:44, 6.76MB/s]\n",
      " 59%|█████▊    | 421M/720M [01:03<00:43, 6.84MB/s]\n",
      " 59%|█████▊    | 422M/720M [01:03<00:45, 6.51MB/s]\n",
      " 59%|█████▉    | 423M/720M [01:03<00:42, 7.04MB/s]\n",
      " 59%|█████▉    | 424M/720M [01:03<00:44, 6.69MB/s]\n",
      " 59%|█████▉    | 425M/720M [01:03<00:41, 7.05MB/s]\n",
      " 59%|█████▉    | 426M/720M [01:03<00:52, 5.55MB/s]\n",
      " 59%|█████▉    | 427M/720M [01:04<00:45, 6.41MB/s]\n",
      " 60%|█████▉    | 428M/720M [01:04<00:42, 6.87MB/s]\n",
      " 60%|█████▉    | 429M/720M [01:04<00:46, 6.21MB/s]\n",
      " 60%|█████▉    | 430M/720M [01:04<00:44, 6.57MB/s]\n",
      " 60%|█████▉    | 431M/720M [01:04<00:40, 7.07MB/s]\n",
      " 60%|██████    | 433M/720M [01:04<00:42, 6.78MB/s]\n",
      " 60%|██████    | 434M/720M [01:04<00:42, 6.74MB/s]\n",
      " 60%|██████    | 435M/720M [01:05<00:39, 7.19MB/s]\n",
      " 61%|██████    | 436M/720M [01:05<00:40, 7.09MB/s]\n",
      " 61%|██████    | 437M/720M [01:05<00:38, 7.43MB/s]\n",
      " 61%|██████    | 438M/720M [01:05<00:37, 7.51MB/s]\n",
      " 61%|██████    | 439M/720M [01:05<00:39, 7.11MB/s]\n",
      " 61%|██████    | 440M/720M [01:05<00:37, 7.42MB/s]\n",
      " 61%|██████▏   | 441M/720M [01:05<00:36, 7.72MB/s]\n",
      " 61%|██████▏   | 442M/720M [01:06<00:35, 7.90MB/s]\n",
      " 62%|██████▏   | 444M/720M [01:06<00:35, 7.87MB/s]\n",
      " 62%|██████▏   | 445M/720M [01:06<00:34, 8.00MB/s]\n",
      " 62%|██████▏   | 446M/720M [01:06<00:37, 7.31MB/s]\n",
      " 62%|██████▏   | 447M/720M [01:06<00:36, 7.58MB/s]\n",
      " 62%|██████▏   | 448M/720M [01:06<00:34, 7.91MB/s]\n",
      " 62%|██████▏   | 449M/720M [01:06<00:38, 7.10MB/s]\n",
      " 63%|██████▎   | 450M/720M [01:07<00:36, 7.36MB/s]\n",
      " 63%|██████▎   | 451M/720M [01:07<00:39, 6.85MB/s]\n",
      " 63%|██████▎   | 452M/720M [01:07<00:49, 5.41MB/s]\n",
      " 63%|██████▎   | 453M/720M [01:07<00:54, 4.88MB/s]\n",
      " 63%|██████▎   | 454M/720M [01:07<00:47, 5.60MB/s]\n",
      " 63%|██████▎   | 455M/720M [01:08<00:46, 5.72MB/s]\n",
      " 63%|██████▎   | 456M/720M [01:08<00:43, 6.06MB/s]\n",
      " 64%|██████▎   | 457M/720M [01:08<00:39, 6.64MB/s]\n",
      " 64%|██████▎   | 458M/720M [01:08<00:36, 7.09MB/s]\n",
      " 64%|██████▍   | 459M/720M [01:08<00:36, 7.16MB/s]\n",
      " 64%|██████▍   | 460M/720M [01:08<00:36, 7.05MB/s]\n",
      " 64%|██████▍   | 461M/720M [01:08<00:35, 7.19MB/s]\n",
      " 64%|██████▍   | 462M/720M [01:09<00:36, 7.00MB/s]\n",
      " 64%|██████▍   | 463M/720M [01:09<00:35, 7.13MB/s]\n",
      " 65%|██████▍   | 465M/720M [01:09<00:35, 7.21MB/s]\n",
      " 65%|██████▍   | 466M/720M [01:09<00:33, 7.49MB/s]\n",
      " 65%|██████▍   | 467M/720M [01:09<00:33, 7.64MB/s]\n",
      " 65%|██████▍   | 468M/720M [01:09<00:32, 7.82MB/s]\n",
      " 65%|██████▌   | 469M/720M [01:09<00:32, 7.70MB/s]\n",
      " 65%|██████▌   | 470M/720M [01:10<00:31, 7.99MB/s]\n",
      " 65%|██████▌   | 471M/720M [01:10<00:30, 8.29MB/s]\n",
      " 66%|██████▌   | 472M/720M [01:10<00:29, 8.41MB/s]\n",
      " 66%|██████▌   | 473M/720M [01:10<00:29, 8.34MB/s]\n",
      " 66%|██████▌   | 474M/720M [01:10<00:29, 8.37MB/s]\n",
      " 66%|██████▌   | 475M/720M [01:10<00:29, 8.37MB/s]\n",
      " 66%|██████▌   | 476M/720M [01:10<00:33, 7.17MB/s]\n",
      " 66%|██████▋   | 477M/720M [01:11<00:34, 6.96MB/s]\n",
      " 66%|██████▋   | 478M/720M [01:11<00:32, 7.44MB/s]\n",
      " 67%|██████▋   | 479M/720M [01:11<00:31, 7.72MB/s]\n",
      " 67%|██████▋   | 480M/720M [01:11<00:30, 7.91MB/s]\n",
      " 67%|██████▋   | 481M/720M [01:11<00:30, 7.86MB/s]\n",
      " 67%|██████▋   | 482M/720M [01:11<00:28, 8.25MB/s]\n",
      " 67%|██████▋   | 484M/720M [01:11<00:26, 9.03MB/s]\n",
      " 67%|██████▋   | 485M/720M [01:11<00:25, 9.15MB/s]\n",
      " 68%|██████▊   | 486M/720M [01:12<00:26, 8.65MB/s]\n",
      " 68%|██████▊   | 487M/720M [01:12<00:26, 8.70MB/s]\n",
      " 68%|██████▊   | 488M/720M [01:12<00:26, 8.75MB/s]\n",
      " 68%|██████▊   | 489M/720M [01:12<00:26, 8.73MB/s]\n",
      " 68%|██████▊   | 490M/720M [01:12<00:26, 8.60MB/s]\n",
      " 68%|██████▊   | 491M/720M [01:12<00:29, 7.79MB/s]\n",
      " 68%|██████▊   | 492M/720M [01:12<00:27, 8.13MB/s]\n",
      " 69%|██████▊   | 494M/720M [01:12<00:25, 8.98MB/s]\n",
      " 69%|██████▉   | 495M/720M [01:13<00:25, 8.85MB/s]\n",
      " 69%|██████▉   | 496M/720M [01:13<00:27, 7.99MB/s]\n",
      " 69%|██████▉   | 497M/720M [01:13<00:27, 8.12MB/s]\n",
      " 69%|██████▉   | 499M/720M [01:13<00:30, 7.26MB/s]\n",
      " 69%|██████▉   | 500M/720M [01:13<00:28, 7.77MB/s]\n",
      " 70%|██████▉   | 501M/720M [01:13<00:28, 7.58MB/s]\n",
      " 70%|██████▉   | 502M/720M [01:14<00:31, 6.99MB/s]\n",
      " 70%|██████▉   | 503M/720M [01:14<00:29, 7.29MB/s]\n",
      " 70%|███████   | 504M/720M [01:14<00:28, 7.54MB/s]\n",
      " 70%|███████   | 505M/720M [01:14<00:26, 8.10MB/s]\n",
      " 70%|███████   | 506M/720M [01:14<00:26, 8.11MB/s]\n",
      " 70%|███████   | 507M/720M [01:14<00:25, 8.25MB/s]\n",
      " 71%|███████   | 508M/720M [01:14<00:25, 8.39MB/s]\n",
      " 71%|███████   | 509M/720M [01:14<00:25, 8.29MB/s]\n",
      " 71%|███████   | 510M/720M [01:15<00:24, 8.47MB/s]\n",
      " 71%|███████   | 511M/720M [01:15<00:26, 7.85MB/s]\n",
      " 71%|███████▏  | 513M/720M [01:15<00:23, 8.84MB/s]\n",
      " 71%|███████▏  | 514M/720M [01:15<00:23, 8.65MB/s]\n",
      " 72%|███████▏  | 515M/720M [01:15<00:25, 7.92MB/s]\n",
      " 72%|███████▏  | 516M/720M [01:15<00:24, 8.14MB/s]\n",
      " 72%|███████▏  | 518M/720M [01:15<00:22, 8.85MB/s]\n",
      " 72%|███████▏  | 519M/720M [01:16<00:22, 8.79MB/s]\n",
      " 72%|███████▏  | 520M/720M [01:16<00:22, 9.03MB/s]\n",
      " 72%|███████▏  | 521M/720M [01:16<00:22, 8.71MB/s]\n",
      " 73%|███████▎  | 522M/720M [01:16<00:22, 8.60MB/s]\n",
      " 73%|███████▎  | 523M/720M [01:16<00:22, 8.64MB/s]\n",
      " 73%|███████▎  | 524M/720M [01:16<00:23, 8.25MB/s]\n",
      " 73%|███████▎  | 525M/720M [01:16<00:25, 7.62MB/s]\n",
      " 73%|███████▎  | 526M/720M [01:16<00:24, 7.81MB/s]\n",
      " 73%|███████▎  | 527M/720M [01:17<00:24, 7.78MB/s]\n",
      " 73%|███████▎  | 528M/720M [01:17<00:25, 7.35MB/s]\n",
      " 74%|███████▎  | 530M/720M [01:17<00:25, 7.38MB/s]\n",
      " 74%|███████▎  | 531M/720M [01:17<00:26, 7.08MB/s]\n",
      " 74%|███████▍  | 532M/720M [01:17<00:29, 6.47MB/s]\n",
      " 74%|███████▍  | 533M/720M [01:17<00:27, 6.86MB/s]\n",
      " 74%|███████▍  | 534M/720M [01:18<00:26, 7.07MB/s]\n",
      " 74%|███████▍  | 535M/720M [01:18<00:27, 6.72MB/s]\n",
      " 74%|███████▍  | 536M/720M [01:18<00:26, 7.03MB/s]\n",
      " 75%|███████▍  | 537M/720M [01:18<00:26, 7.02MB/s]\n",
      " 75%|███████▍  | 538M/720M [01:18<00:24, 7.36MB/s]\n",
      " 75%|███████▍  | 539M/720M [01:18<00:23, 7.67MB/s]\n",
      " 75%|███████▌  | 540M/720M [01:18<00:22, 7.95MB/s]\n",
      " 75%|███████▌  | 541M/720M [01:19<00:32, 5.45MB/s]\n",
      " 75%|███████▌  | 542M/720M [01:19<00:31, 5.61MB/s]\n",
      " 75%|███████▌  | 543M/720M [01:19<00:31, 5.65MB/s]\n",
      " 76%|███████▌  | 544M/720M [01:19<00:30, 5.76MB/s]\n",
      " 76%|███████▌  | 545M/720M [01:19<00:30, 5.65MB/s]\n",
      " 76%|███████▌  | 546M/720M [01:20<00:28, 6.18MB/s]\n",
      " 76%|███████▌  | 547M/720M [01:20<00:25, 6.62MB/s]\n",
      " 76%|███████▌  | 548M/720M [01:20<00:26, 6.54MB/s]\n",
      " 76%|███████▋  | 549M/720M [01:20<00:24, 7.01MB/s]\n",
      " 77%|███████▋  | 551M/720M [01:20<00:23, 7.21MB/s]\n",
      " 77%|███████▋  | 552M/720M [01:20<00:25, 6.70MB/s]\n",
      " 77%|███████▋  | 553M/720M [01:20<00:22, 7.32MB/s]\n",
      " 77%|███████▋  | 554M/720M [01:21<00:21, 7.69MB/s]\n",
      " 77%|███████▋  | 555M/720M [01:21<00:20, 8.07MB/s]\n",
      " 77%|███████▋  | 556M/720M [01:21<00:20, 7.97MB/s]\n",
      " 77%|███████▋  | 557M/720M [01:21<00:19, 8.32MB/s]\n",
      " 78%|███████▊  | 558M/720M [01:21<00:19, 8.35MB/s]\n",
      " 78%|███████▊  | 559M/720M [01:21<00:18, 8.57MB/s]\n",
      " 78%|███████▊  | 560M/720M [01:21<00:18, 8.70MB/s]\n",
      " 78%|███████▊  | 562M/720M [01:21<00:19, 8.28MB/s]\n",
      " 78%|███████▊  | 563M/720M [01:22<00:19, 8.14MB/s]\n",
      " 78%|███████▊  | 564M/720M [01:22<00:18, 8.28MB/s]\n",
      " 78%|███████▊  | 565M/720M [01:22<00:17, 8.63MB/s]\n",
      " 79%|███████▊  | 566M/720M [01:22<00:17, 8.84MB/s]\n",
      " 79%|███████▉  | 567M/720M [01:22<00:16, 9.39MB/s]\n",
      " 79%|███████▉  | 568M/720M [01:22<00:16, 9.38MB/s]\n",
      " 79%|███████▉  | 569M/720M [01:22<00:15, 9.45MB/s]\n",
      " 79%|███████▉  | 570M/720M [01:22<00:17, 8.77MB/s]\n",
      " 79%|███████▉  | 571M/720M [01:23<00:16, 9.16MB/s]\n",
      " 80%|███████▉  | 573M/720M [01:23<00:16, 8.84MB/s]\n",
      " 80%|███████▉  | 574M/720M [01:23<00:17, 8.52MB/s]\n",
      " 80%|███████▉  | 575M/720M [01:23<00:16, 8.52MB/s]\n",
      " 80%|████████  | 576M/720M [01:23<00:16, 8.50MB/s]\n",
      " 80%|████████  | 577M/720M [01:23<00:19, 7.17MB/s]\n",
      " 80%|████████  | 578M/720M [01:23<00:19, 7.21MB/s]\n",
      " 81%|████████  | 580M/720M [01:24<00:17, 8.04MB/s]\n",
      " 81%|████████  | 581M/720M [01:24<00:16, 8.19MB/s]\n",
      " 81%|████████  | 582M/720M [01:24<00:16, 8.45MB/s]\n",
      " 81%|████████  | 583M/720M [01:24<00:16, 8.32MB/s]\n",
      " 81%|████████  | 584M/720M [01:24<00:15, 8.54MB/s]\n",
      " 81%|████████▏ | 585M/720M [01:24<00:15, 8.62MB/s]\n",
      " 81%|████████▏ | 586M/720M [01:24<00:17, 7.68MB/s]\n",
      " 82%|████████▏ | 587M/720M [01:25<00:17, 7.63MB/s]\n",
      " 82%|████████▏ | 588M/720M [01:25<00:20, 6.30MB/s]\n",
      " 82%|████████▏ | 589M/720M [01:25<00:23, 5.46MB/s]\n",
      " 82%|████████▏ | 590M/720M [01:25<00:20, 6.16MB/s]\n",
      " 82%|████████▏ | 591M/720M [01:25<00:21, 6.06MB/s]\n",
      " 82%|████████▏ | 592M/720M [01:25<00:19, 6.59MB/s]\n",
      " 82%|████████▏ | 593M/720M [01:26<00:17, 7.22MB/s]\n",
      " 83%|████████▎ | 595M/720M [01:26<00:16, 7.48MB/s]\n",
      " 83%|████████▎ | 596M/720M [01:26<00:16, 7.41MB/s]\n",
      " 83%|████████▎ | 597M/720M [01:26<00:19, 6.17MB/s]\n",
      " 83%|████████▎ | 598M/720M [01:26<00:18, 6.66MB/s]\n",
      " 83%|████████▎ | 599M/720M [01:26<00:16, 7.23MB/s]\n",
      " 83%|████████▎ | 600M/720M [01:26<00:17, 6.90MB/s]\n",
      " 84%|████████▎ | 601M/720M [01:27<00:16, 7.11MB/s]\n",
      " 84%|████████▎ | 602M/720M [01:27<00:15, 7.47MB/s]\n",
      " 84%|████████▍ | 603M/720M [01:27<00:17, 6.85MB/s]\n",
      " 84%|████████▍ | 604M/720M [01:27<00:15, 7.48MB/s]\n",
      " 84%|████████▍ | 605M/720M [01:27<00:15, 7.35MB/s]\n",
      " 84%|████████▍ | 606M/720M [01:27<00:14, 7.67MB/s]\n",
      " 84%|████████▍ | 607M/720M [01:27<00:15, 7.27MB/s]\n",
      " 85%|████████▍ | 608M/720M [01:28<00:14, 7.70MB/s]\n",
      " 85%|████████▍ | 610M/720M [01:28<00:13, 7.98MB/s]\n",
      " 85%|████████▍ | 611M/720M [01:28<00:13, 7.98MB/s]\n",
      " 85%|████████▌ | 612M/720M [01:28<00:12, 8.33MB/s]\n",
      " 85%|████████▌ | 613M/720M [01:28<00:11, 8.90MB/s]\n",
      " 85%|████████▌ | 614M/720M [01:28<00:12, 8.72MB/s]\n",
      " 86%|████████▌ | 616M/720M [01:28<00:11, 8.76MB/s]\n",
      " 86%|████████▌ | 617M/720M [01:29<00:11, 8.81MB/s]\n",
      " 86%|████████▌ | 618M/720M [01:29<00:11, 8.97MB/s]\n",
      " 86%|████████▌ | 619M/720M [01:29<00:11, 9.15MB/s]\n",
      " 86%|████████▌ | 620M/720M [01:29<00:10, 9.73MB/s]\n",
      " 86%|████████▋ | 621M/720M [01:29<00:10, 9.17MB/s]\n",
      " 86%|████████▋ | 622M/720M [01:29<00:11, 8.38MB/s]\n",
      " 87%|████████▋ | 623M/720M [01:29<00:11, 8.40MB/s]\n",
      " 87%|████████▋ | 624M/720M [01:29<00:11, 8.44MB/s]\n",
      " 87%|████████▋ | 625M/720M [01:30<00:11, 8.38MB/s]\n",
      " 87%|████████▋ | 627M/720M [01:30<00:11, 8.06MB/s]\n",
      " 87%|████████▋ | 628M/720M [01:30<00:11, 8.12MB/s]\n",
      " 87%|████████▋ | 629M/720M [01:30<00:13, 6.91MB/s]\n",
      " 88%|████████▊ | 630M/720M [01:30<00:16, 5.55MB/s]\n",
      " 88%|████████▊ | 631M/720M [01:30<00:14, 6.18MB/s]\n",
      " 88%|████████▊ | 632M/720M [01:31<00:12, 6.78MB/s]\n",
      " 88%|████████▊ | 633M/720M [01:31<00:11, 7.23MB/s]\n",
      " 88%|████████▊ | 634M/720M [01:31<00:12, 6.76MB/s]\n",
      " 88%|████████▊ | 635M/720M [01:31<00:12, 7.03MB/s]\n",
      " 88%|████████▊ | 636M/720M [01:31<00:12, 6.62MB/s]\n",
      " 89%|████████▊ | 637M/720M [01:31<00:12, 6.53MB/s]\n",
      " 89%|████████▊ | 639M/720M [01:32<00:10, 7.60MB/s]\n",
      " 89%|████████▉ | 640M/720M [01:32<00:09, 8.01MB/s]\n",
      " 89%|████████▉ | 641M/720M [01:32<00:09, 8.29MB/s]\n",
      " 89%|████████▉ | 642M/720M [01:32<00:09, 8.50MB/s]\n",
      " 89%|████████▉ | 643M/720M [01:32<00:09, 8.36MB/s]\n",
      " 89%|████████▉ | 644M/720M [01:32<00:08, 8.48MB/s]\n",
      " 90%|████████▉ | 645M/720M [01:32<00:10, 7.41MB/s]\n",
      " 90%|████████▉ | 646M/720M [01:32<00:09, 7.72MB/s]\n",
      " 90%|████████▉ | 647M/720M [01:33<00:08, 8.18MB/s]\n",
      " 90%|█████████ | 648M/720M [01:33<00:08, 8.00MB/s]\n",
      " 90%|█████████ | 649M/720M [01:33<00:08, 8.50MB/s]\n",
      " 90%|█████████ | 650M/720M [01:33<00:08, 8.29MB/s]\n",
      " 90%|█████████ | 651M/720M [01:33<00:10, 6.32MB/s]\n",
      " 91%|█████████ | 652M/720M [01:33<00:09, 6.95MB/s]\n",
      " 91%|█████████ | 653M/720M [01:33<00:09, 7.33MB/s]\n",
      " 91%|█████████ | 654M/720M [01:34<00:08, 7.55MB/s]\n",
      " 91%|█████████ | 655M/720M [01:34<00:08, 7.82MB/s]\n",
      " 91%|█████████ | 656M/720M [01:34<00:08, 7.29MB/s]\n",
      " 91%|█████████▏| 657M/720M [01:34<00:08, 7.54MB/s]\n",
      " 92%|█████████▏| 659M/720M [01:34<00:07, 7.96MB/s]\n",
      " 92%|█████████▏| 660M/720M [01:34<00:07, 8.30MB/s]\n",
      " 92%|█████████▏| 662M/720M [01:34<00:06, 9.02MB/s]\n",
      " 92%|█████████▏| 663M/720M [01:35<00:06, 8.89MB/s]\n",
      " 92%|█████████▏| 664M/720M [01:35<00:06, 8.43MB/s]\n",
      " 92%|█████████▏| 665M/720M [01:35<00:06, 8.45MB/s]\n",
      " 93%|█████████▎| 666M/720M [01:35<00:06, 8.67MB/s]\n",
      " 93%|█████████▎| 667M/720M [01:35<00:05, 8.82MB/s]\n",
      " 93%|█████████▎| 668M/720M [01:35<00:06, 7.75MB/s]\n",
      " 93%|█████████▎| 669M/720M [01:35<00:07, 6.75MB/s]\n",
      " 93%|█████████▎| 670M/720M [01:36<00:09, 5.28MB/s]\n",
      " 93%|█████████▎| 671M/720M [01:36<00:08, 5.92MB/s]\n",
      " 93%|█████████▎| 672M/720M [01:36<00:07, 6.19MB/s]\n",
      " 94%|█████████▎| 673M/720M [01:36<00:08, 5.25MB/s]\n",
      " 94%|█████████▎| 674M/720M [01:36<00:07, 5.96MB/s]\n",
      " 94%|█████████▍| 675M/720M [01:36<00:06, 6.48MB/s]\n",
      " 94%|█████████▍| 676M/720M [01:37<00:06, 6.81MB/s]\n",
      " 94%|█████████▍| 677M/720M [01:37<00:06, 6.72MB/s]\n",
      " 94%|█████████▍| 678M/720M [01:37<00:05, 7.02MB/s]\n",
      " 94%|█████████▍| 679M/720M [01:37<00:05, 7.43MB/s]\n",
      " 95%|█████████▍| 681M/720M [01:37<00:05, 7.69MB/s]\n",
      " 95%|█████████▍| 682M/720M [01:37<00:04, 8.30MB/s]\n",
      " 95%|█████████▍| 683M/720M [01:37<00:04, 8.25MB/s]\n",
      " 95%|█████████▌| 684M/720M [01:38<00:04, 8.15MB/s]\n",
      " 95%|█████████▌| 685M/720M [01:38<00:04, 8.09MB/s]\n",
      " 95%|█████████▌| 686M/720M [01:38<00:03, 8.47MB/s]\n",
      " 95%|█████████▌| 687M/720M [01:38<00:03, 8.58MB/s]\n",
      " 96%|█████████▌| 688M/720M [01:38<00:03, 8.45MB/s]\n",
      " 96%|█████████▌| 689M/720M [01:38<00:03, 8.48MB/s]\n",
      " 96%|█████████▌| 690M/720M [01:38<00:03, 7.61MB/s]\n",
      " 96%|█████████▌| 691M/720M [01:38<00:03, 7.67MB/s]\n",
      " 96%|█████████▌| 692M/720M [01:39<00:03, 8.07MB/s]\n",
      " 96%|█████████▋| 693M/720M [01:39<00:03, 8.00MB/s]\n",
      " 96%|█████████▋| 694M/720M [01:39<00:03, 8.42MB/s]\n",
      " 97%|█████████▋| 696M/720M [01:39<00:02, 9.19MB/s]\n",
      " 97%|█████████▋| 697M/720M [01:39<00:02, 8.98MB/s]\n",
      " 97%|█████████▋| 698M/720M [01:39<00:02, 8.00MB/s]\n",
      " 97%|█████████▋| 699M/720M [01:39<00:02, 8.06MB/s]\n",
      " 97%|█████████▋| 700M/720M [01:39<00:02, 8.41MB/s]\n",
      " 97%|█████████▋| 701M/720M [01:40<00:02, 8.49MB/s]\n",
      " 98%|█████████▊| 703M/720M [01:40<00:02, 8.34MB/s]\n",
      " 98%|█████████▊| 704M/720M [01:40<00:02, 7.37MB/s]\n",
      " 98%|█████████▊| 705M/720M [01:40<00:02, 6.87MB/s]\n",
      " 98%|█████████▊| 706M/720M [01:40<00:01, 8.23MB/s]\n",
      " 98%|█████████▊| 707M/720M [01:40<00:01, 7.33MB/s]\n",
      " 98%|█████████▊| 708M/720M [01:41<00:02, 5.18MB/s]\n",
      " 99%|█████████▊| 709M/720M [01:41<00:01, 5.64MB/s]\n",
      " 99%|█████████▊| 710M/720M [01:41<00:01, 5.89MB/s]\n",
      " 99%|█████████▉| 711M/720M [01:41<00:01, 6.33MB/s]\n",
      " 99%|█████████▉| 713M/720M [01:41<00:00, 7.11MB/s]\n",
      " 99%|█████████▉| 714M/720M [01:41<00:00, 7.43MB/s]\n",
      " 99%|█████████▉| 715M/720M [01:42<00:00, 7.53MB/s]\n",
      " 99%|█████████▉| 716M/720M [01:42<00:00, 7.77MB/s]\n",
      "100%|█████████▉| 717M/720M [01:42<00:00, 8.09MB/s]\n",
      "100%|█████████▉| 718M/720M [01:42<00:00, 8.39MB/s]\n",
      "100%|█████████▉| 719M/720M [01:42<00:00, 8.34MB/s]\n",
      "100%|██████████| 720M/720M [01:42<00:00, 7.01MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=13JG4Sh7Fpad8O6eB_fQe7C2wQmO7hRtj\n",
      "To: d:\\College\\Assignments\\NNDL_Project\\Hebbnet_backbone.zip\n",
      "\n",
      "  0%|          | 0.00/3.98k [00:00<?, ?B/s]\n",
      "100%|██████████| 3.98k/3.98k [00:00<?, ?B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Extracting Dataset and Copying file (This might take a while)\"\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/detectron2.git\n",
    "\n",
    "!pip install gdown -q || echo \"Error installing gdown\"\n",
    "!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html -q || echo \"Error installing torch and related packages\"\n",
    "!pip install fvcore -q || echo \"Error installing fvcore\"\n",
    "!pip install opencv-python -q || echo \"Error installing opencv-python\"\n",
    "!pip install pycocotools -q || echo \"Error installing pycocotools\"\n",
    "!pip install cloudpickle -q || echo \"Error installing cloudpickle\"\n",
    "!pip install omegaconf -q || echo \"Error installing omegaconf\"\n",
    "!pip install matplotlib -q || echo \"Error installing matplotlib\"\n",
    "!pip install tensorboard -q || echo \"Error installing tensorboard\"\n",
    "\n",
    "!echo \"Downloading Dataset (This might take a while)\"\n",
    "!gdown https://drive.google.com/uc?id=1MM6kODxnDvkVzzOuOYYbwrP5uou1DOC- -O datasets.zip\n",
    "!gdown https://drive.google.com/uc?id=13JG4Sh7Fpad8O6eB_fQe7C2wQmO7hRtj -O Hebbnet_backbone.zip\n",
    "\n",
    "!echo \"Extracting Dataset and Copying file (This might take a while)\"\n",
    "!python -c \"import zipfile; zipfile.ZipFile('datasets.zip', 'r').extractall('.')\"\n",
    "!python -c \"import zipfile; zipfile.ZipFile('Hebbnet_backbone.zip', 'r').extractall('Hebbnet_backbone')\"\n",
    "!python -c \"import shutil; shutil.move('Hebbnet_backbone/__init__.py', './detectron2/detectron2/modeling/backbone/__init__.py'); shutil.move('Hebbnet_backbone/hebbnet_backbone.py', './detectron2/detectron2/modeling/backbone/hebbnet_backbone.py'); shutil.move('Hebbnet_backbone/hebbnet_backbone.yaml', './detectron2/configs/COCO-Detection/hebbnet_backbone.yaml')\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "// Only run this if in Linux:\n",
    "!pip install git+https://github.com/facebookresearch/detectron2.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !! After the above stage please move this notebook inside the `detectron2` directory, and set the following variable to the same path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_detectron2 = r\"/home/ppathak/Praddy_CSC578/detectron2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ppathak/Praddy_CSC578/detectron2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ppathak/miniconda3/envs/hebdet/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Setting up runtime Work Directory and Importing Libraries\n",
    "\n",
    "import os\n",
    "os.chdir(PATH_detectron2)\n",
    "print(os.getcwd())\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "import torch\n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "import logging\n",
    "\n",
    "# Set logging level to WARNING to suppress detailed model architecture output\n",
    "logging.getLogger(\"detectron2\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details about the dataset:\n",
    "\n",
    "* This is a custom dataset created from COCO-Dataset\n",
    "* It is a detection dataset only containing one object - `dog`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the custom dataset for training:\n",
    "\n",
    "register_coco_instances(\"coco_train_dog\", {}, \"../datasets/coco/annotations/dog_instances_train2017.json\", \"../datasets/coco/train2017_dog\")\n",
    "register_coco_instances(\"coco_val_dog\", {}, \"../datasets/coco/annotations/dog_instances_val2017.json\", \"../datasets/coco/val2017_dog\")\n",
    "\n",
    "my_dataset_metadata = MetadataCatalog.get(\"coco_train_dog\")\n",
    "my_dataset_metadata.thing_classes = [\"dog\"]\n",
    "dataset_dicts = DatasetCatalog.get(\"coco_train_dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Model Design and Implementation\n",
    "\n",
    "## 2a. We have used `Resnet-FRCNN` as our control model:\n",
    "* We employ `GeneralizedRCNN` architecture to later replace the `Resnet` backbone with `HebbNet`\n",
    "* The traditional `FRCNN` Architecture is as shown below:\n",
    "\n",
    "   <a href=\"https://ibb.co/SJt1ZDP\"><img src=\"https://i.ibb.co/4J8D0w7/detectron2.png\" alt=\"detectron2\" border=\"0\"></a>\n",
    "\n",
    "* ### The Architecture has the following blocks:\n",
    "\n",
    "    * **Backbone Network** (`Resnet`) - Is responsible for creating feature maps from the images:\n",
    "        * It learns feature maps that help `RPN` (Region Proposal Network) and `ROIHeads` to do their tasks.\n",
    "        * It mainly composes of convolution layers and pooling layers like typical CNN based feature extractors.\n",
    "        * The Feature extraction happens in form of convolution filters.\n",
    "        * It also has 3 stage: `res2`, `res3`, `res4` and, `res5`.\n",
    "\n",
    "    * **Region Proposal Network (`RPN`)** - Is responsible for  producing Regions boxes:\n",
    "        * It learns to propose which region in the images could have potential bounding boxes.\n",
    "        * It uses 2D convolutional layers (e.g., a 3x3 filter) to generate these predictions, sliding over the feature map and predicting class scores and box offsets.\n",
    "        * The input to the `RPN` is the feature map produced by the backbone network (e.g., `ResNet`), typically with a size of `𝐻×𝑊×𝐶`.\n",
    "        * The output consists of objectness scores and bounding box refinements for each anchor at each spatial location on the feature map.\n",
    "\n",
    "    * **ROIHeads** - classifies the region proposals generated by the RPN and refining their bounding box coordinates:\n",
    "        * The input to the `ROIHeads` is the region proposals generated by the `RPN`, along with the feature map from the backbone network.\n",
    "        * Its output is the final class scores and refined bounding box coordinates for each region proposal.\n",
    "        * The `ROIHeads` use `RoIAlign` to extract fixed-size features from the feature map, followed by fully connected layers to classify and refine the bounding boxes for each proposal.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Training and Evaluating The `FRCNN` with `Resnet` Backbone for control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1a. Set the configuration to load teh Resent Based FRCNN architecture:\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"configs/COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\") #ImageNet pre-trained\n",
    "cfg.OUTPUT_DIR = f\"{PATH_detectron2}/output/dog_resnet_test\"\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"coco_train_dog\",)\n",
    "cfg.DATASETS.TEST = (\"coco_val_dog\",)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.5\n",
    "cfg.SOLVER.IMS_PER_BATCH = 64\n",
    "cfg.SOLVER.BASE_LR = 0.0025\n",
    "cfg.SOLVER.MAX_ITER = 50000\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 1000\n",
    "cfg.TEST.EVAL_PERIOD = 1000\n",
    "\n",
    "# run on GPU\n",
    "cfg.MODEL.DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1b. Load the Trainer for the defiend Resnet-FRCNN architecture and train:\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mDefaultTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m trainer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mDEVICE)\n\u001b[1;32m      6\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/Praddy_CSC578/detectron2/detectron2/engine/defaults.py:410\u001b[0m, in \u001b[0;36mDefaultTrainer.__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    407\u001b[0m cfg \u001b[38;5;241m=\u001b[39m DefaultTrainer\u001b[38;5;241m.\u001b[39mauto_scale_workers(cfg, comm\u001b[38;5;241m.\u001b[39mget_world_size())\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# Assume these objects must be constructed in this order.\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_optimizer(cfg, model)\n\u001b[1;32m    412\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_train_loader(cfg)\n",
      "File \u001b[0;32m~/Praddy_CSC578/detectron2/detectron2/engine/defaults.py:550\u001b[0m, in \u001b[0;36mDefaultTrainer.build_model\u001b[0;34m(cls, cfg)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(\u001b[38;5;28mcls\u001b[39m, cfg):\n\u001b[1;32m    543\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;124;03m        torch.nn.Module:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Overwrite it if you'd like a different model.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 550\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    552\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model))\n",
      "File \u001b[0;32m~/Praddy_CSC578/detectron2/detectron2/modeling/meta_arch/build.py:23\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     21\u001b[0m meta_arch \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mMETA_ARCHITECTURE\n\u001b[1;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m META_ARCH_REGISTRY\u001b[38;5;241m.\u001b[39mget(meta_arch)(cfg)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m _log_api_usage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodeling.meta_arch.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m meta_arch)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/hebdet/lib/python3.8/site-packages/torch/nn/modules/module.py:673\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    670\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hebdet/lib/python3.8/site-packages/torch/nn/modules/module.py:387\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 387\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    391\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    392\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    398\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hebdet/lib/python3.8/site-packages/torch/nn/modules/module.py:387\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 387\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    391\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    392\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    398\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 387 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/hebdet/lib/python3.8/site-packages/torch/nn/modules/module.py:387\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 387\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    391\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    392\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    398\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hebdet/lib/python3.8/site-packages/torch/nn/modules/module.py:430\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, buf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers[key] \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/hebdet/lib/python3.8/site-packages/torch/nn/modules/module.py:671\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    670\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "# 1b. Load the Trainer for the defiend Resnet-FRCNN architecture and train:\n",
    "\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.model.to(cfg.MODEL.DEVICE)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1c. Saving and Evaluation of the model\n",
    "\n",
    "output_dir = f\"{PATH_detectron2}/dog_resnet_test\"\n",
    "cfg.MODEL.WEIGHTS = output_dir + '/RESNET_BackBone_model_final.pth'\n",
    "\n",
    "trainer.model.eval()\n",
    "\n",
    "evaluator = COCOEvaluator(\"coco_val_subset\", (\"bbox\",), False, output_dir=output_dir)\n",
    "val_loader = build_detection_test_loader(cfg, \"coco_val_dog\")\n",
    "print(inference_on_dataset(trainer.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Model Architecture (`HebbNet-FRCNN`)\n",
    "## 2b. The Custom HebbNet-Backbone FRCNN Architecture:\n",
    "\n",
    "* ### The HebbNet architecure is small:\n",
    "    * **The use of Linear Layers**: All the layers in the architecture are linear layers:\n",
    "        * This was done because implimenting convolution layer hebbian updates was too risky to finish for the time of this project (4 Weeks).\n",
    "        * The Linear layers needed to be reformed in 2D layers, which was done by reshaping them back, to the expected dimension using `reshape(1, num_feature_map_channel, int(width_hideen_layer), int(width_hideen_layer))`.\n",
    "        \n",
    "    * **Layer Dimensions**:\n",
    "        * For purposes of avoiding memory error the input_layer dimensions of the model is `128 x 128 x 3`.\n",
    "        * We have `8` linear hidden layers each of a dimension `1 x 16,384`.\n",
    "        * The feature map is a stack of `8` each of size `128 x 128`.\n",
    "    \n",
    "    * **Connecting with ROIHead**:\n",
    "        * We have **skipped** `RPN` in our implimentation due to integration complexity and time constraints.\n",
    "        * But still we get precomputed Region Proposals as a  default feature of `detectron2` implimentation in abscence of `RPN`.\n",
    "        * The output of `HebbNet` feature maps goes to the `ROIHeads`.\n",
    "\n",
    "## Below is the HebbNet Backbone Architecture code:\n",
    "```python\n",
    "class HebbNet(Backbone):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=(5, 5), stride=2, padding=0)       # Based on testing, doing MaxPool and then adaptive pooling to keep a shape of 80x80 consistent\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((cfg.INPUT.MAX_SIZE_TRAIN, cfg.INPUT.MAX_SIZE_TRAIN))\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.lr = cfg.MODEL.HEBB_LR\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.input_layer_size = cfg.INPUT.MAX_SIZE_TRAIN * cfg.INPUT.MAX_SIZE_TRAIN * 3\n",
    "        self.flattened_size = self.adaptive_pool.output_size[0] * self.adaptive_pool.output_size[1] * 3\n",
    "        self.hidden_layer_size = (cfg.MODEL.ROI_BOX_HEAD.FC_DIM * self.flattened_size) // (3 * cfg.MODEL.NUM_HIDDEN)\n",
    "        self.flatten = nn.Flatten()    \n",
    "        self.layers.append(nn.Linear(self.input_layer_size, self.hidden_layer_size, False))    \n",
    "        for i in range(self.cfg.MODEL.NUM_HIDDEN-1):\n",
    "            self.layers.append(nn.Linear(self.hidden_layer_size, self.hidden_layer_size, False))\n",
    "        # no output layer necessary\n",
    "        # self.classification_weights = nn.Linear(self.hidden_layer_size, output_layer_size, True)\n",
    "\n",
    "        self.activation_threshold_layers = []\n",
    "        self.activation_threshold_layers.append(HebbRuleWithActivationThreshold(hidden_layer_size=self.hidden_layer_size,\n",
    "                                                                input_layer_size=self.flattened_size).to(self.cfg.MODEL.DEVICE))\n",
    "        for i in range(self.cfg.MODEL.NUM_HIDDEN-1):\n",
    "            self.activation_threshold_layers.append(HebbRuleWithActivationThreshold(hidden_layer_size=self.hidden_layer_size,\n",
    "                                                                input_layer_size=self.hidden_layer_size).to(self.cfg.MODEL.DEVICE))\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        self._out_feature_strides = {\"res4\": 4}\n",
    "        self._out_feature_channels = {\"res4\": cfg.MODEL.ROI_BOX_HEAD.FC_DIM}\n",
    "\n",
    "        # initialize dictionary of outputs along forward pass layers / steps\n",
    "        out_features = [\"res4\"]\n",
    "        self._out_features = out_features\n",
    "\n",
    "        # initialize input_layer_size so it can be used by padding_constraints to specify our fixed image size to generalized rcnn\n",
    "        # self.input_layer_size = input_layer_size\n",
    "\n",
    "        # for img and feature visualization\n",
    "        self.img_vis = cfg.MODEL.IMG_VIS\n",
    "        self.feat_vis = cfg.MODEL.FEAT_VIS\n",
    "        self.feat_vis_num = cfg.MODEL.FEAT_VIS_NUM\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importand Note:\n",
    "* The FRCNN with Resnet Backbone uses **pretrained weights** on ImageNet but our HebbNet architecture is learning from scrach in this detection architecture\n",
    "* The Resnet architecture in Resnet Backbone has a larger input `img-size`, allowing for higher feature throughput from the get go\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Training and Evaluating the `FRNCN` with `Hebbnet` Backbone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a. Setting the primary configurations, ensuring we use the [Custom] HebbNet Backbone:\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"configs/COCO-Detection/hebbnet_backbone.yaml\")     # Loading the Custom HebbNet Backbone Configuration template\n",
    "cfg.OUTPUT_DIR = f\"{PATH_detectron2}/output/dog_hebbnet_test\"\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"coco_train_dog\",)\n",
    "cfg.DATASETS.TEST = (\"coco_val_dog\",)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.OUTPUT_LAYER_SIZE = 1\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.5\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1\n",
    "cfg.SOLVER.BASE_LR = .00002\n",
    "cfg.SOLVER.MAX_ITER = 5500*2\n",
    "\n",
    "# run on GPU\n",
    "cfg.MODEL.DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While Loading the secondary custom configurations:\n",
    "- Our input `image-size` is `128x128`, The reason being we cannot train the model for larger `image-size` due to the following problem:\n",
    "    - We run into `CUDA: Out of Memory Model`: Due to the hidden layers having way too many neurons caused due to a lack of Convolution\n",
    "- We are also leaving out `PROPOSAL_GENERATOR` from our model\n",
    "- The Batch size is set to 1, because we are using Hebbian Learning, but also because of memory constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Secondary configs for custom backbone:\n",
    "\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (128,)\n",
    "cfg.INPUT.MIN_SIZE_TRAIN_SAMPLING = \"choice\"\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = 128\n",
    "cfg.INPUT.MIN_SIZE_TEST = 128\n",
    "cfg.INPUT.MAX_SIZE_TEST = 128\n",
    "# cfg.PROPOSAL_GENERATOR: PrecomputedProposals # this may be an option to potentially avoid issues with proposal generation\n",
    "cfg.MODEL.ROI_HEADS.IN_FEATURES: ['res4']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are also major changes to the `ROIHead` and `BoXHead` in FRCNN:\n",
    "    - We opted to using the `StandardROIHeads` because it made the integration of HebbNet Backbone easier\n",
    "    - We are also limited the `Number Of Channels` in the `FilterMaps` that the `ROIHead` can work with to `8` due to GPU memory constraints\n",
    "    - The `Number Of Fully-Connected Layers` in the `FilterMaps` is also `8` due to GPU memory constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.ROI_HEADS.NAME = \"StandardROIHeads\"\n",
    "cfg.MODEL.ROI_BOX_HEAD.NAME = \"FastRCNNConvFCHead\"\n",
    "cfg.MODEL.ROI_BOX_HEAD.FC_DIM = 8           # Fully Connected Channel Depth to 8\n",
    "cfg.MODEL.ROI_BOX_HEAD.CONV_DIM = 8         # Channel Depth to 8\n",
    "cfg.MODEL.ROI_BOX_HEAD.NUM_CONV = 2\n",
    "cfg.MODEL.ROI_BOX_HEAD.NUM_FC = 2\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 9999999999999999999999999999999999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, the following are the additional parameters exclusive to the Hebbian Backbone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.NUM_HIDDEN = 8\n",
    "cfg.MODEL.HEBB_LR = .00000001 # fewest number of zeros \"allowed\" before gradient explosion\n",
    "\n",
    "cfg.MODEL.IMG_VIS = False\n",
    "cfg.MODEL.FEAT_VIS = False\n",
    "cfg.MODEL.FEAT_VIS_NUM = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training Process:\n",
    "* We train using the `detectron2` Pipeline\n",
    "* The dataset as mentioned above is a custom COCO Dataset with only 1 object\n",
    "* For Preprocessing, the `detectron2` pipeline only uses resizing, and normalizing\n",
    "* We are not doing any image-augumentation\n",
    "\n",
    "* Hyper Parameter:\n",
    "    * We use batch size of 1, because of memory constraints and Hebbian Learning\n",
    "    * We have a really small learning rate of just `0.00002`, as a larger learning rate leads to gradient explosion due to sever penalizing from hebbian learning\n",
    "    * We have a really small hebbian learning rate of just `0.00000001`, as a larger learning rate leads to gradient explosion due to sever penalizing from hebbian learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b. Load the Trainer for the defiend Resnet-FRCNN architecture and train:\n",
    "\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.model.to(cfg.MODEL.DEVICE)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2c. Saving and Evaluation of the model\n",
    "\n",
    "output_dir = f\"{PATH_detectron2}/dog_hebbnet_test\"\n",
    "cfg.MODEL.WEIGHTS = output_dir + '/HebbNet_BackBone_model_final.pth'\n",
    "\n",
    "trainer.model.eval()\n",
    "\n",
    "evaluator = COCOEvaluator(\"coco_val_subset\", (\"bbox\",), False, output_dir=output_dir)\n",
    "val_loader = build_detection_test_loader(cfg, \"coco_val_dog\")\n",
    "print(inference_on_dataset(trainer.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation:\n",
    "* Our initial results showed no marginal difference in performance choosing Hebbian Learning.\n",
    "* The evaluation and training of `Resnet-FRCNN` is in the text file in the zip provided.\n",
    "* We used just Average Precision loss to measure the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hebdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
